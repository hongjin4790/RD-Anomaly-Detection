{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터셋 선택 및 하이퍼파라미터 설정\n",
    "▼▼▼▼▼▼▼▼▼▼▼▼▼▼▼▼▼▼▼▼▼▼▼▼▼▼▼▼▼▼▼▼▼▼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음 데이터셋들이 학습됩니다 :  ['bottle', 'cable', 'capsule', 'carpet', 'grid', 'hazelnut', 'leather', 'metal_nut', 'pill', 'screw', 'tile', 'toothbrush', 'transistor', 'wood', 'zipper']\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import natsort\n",
    "import os\n",
    "\n",
    "folder_list = os.listdir(\"./data\")\n",
    "item_list = natsort.natsorted(folder_list)\n",
    "\n",
    "print(\"다음 데이터셋들이 학습됩니다 : \", item_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#최소10, 200~400 추천, 10단위로 pth가 저장됨\n",
    "epochs = 200\n",
    "batch_size = 16\n",
    "\n",
    "#3090 24GB에서 64까지 사용 가능했음\n",
    "learning_rate = 0.005\n",
    "image_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from dataset import get_data_transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from ConvNext_V1_RD_study import convnext_base\n",
    "from OCE import BN_layer, AttnBottleneck\n",
    "from dataset import RD_Dataset\n",
    "from de_ConvNext import de_convnext_base\n",
    "import torch.backends.cudnn as cudnn\n",
    "import argparse\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fucntion(a, b):\n",
    "    #mse_loss = torch.nn.MSELoss()\n",
    "    cos_loss = torch.nn.CosineSimilarity()\n",
    "    loss = 0\n",
    "    for item in range(len(a)):\n",
    "        #print(a[item].shape)\n",
    "        #print(b[item].shape)\n",
    "        #loss += 0.1*mse_loss(a[item], b[item])\n",
    "        loss += torch.mean(1-cos_loss(a[item].view(a[item].shape[0],-1),\n",
    "                                      b[item].view(b[item].shape[0],-1)))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_concat(a, b):\n",
    "    mse_loss = torch.nn.MSELoss()\n",
    "    cos_loss = torch.nn.CosineSimilarity()\n",
    "    loss = 0\n",
    "    a_map = []\n",
    "    b_map = []\n",
    "    size = a[0].shape[-1]\n",
    "    for item in range(len(a)):\n",
    "        #loss += mse_loss(a[item], b[item])\n",
    "        a_map.append(F.interpolate(a[item], size=size, mode='bilinear', align_corners=True))\n",
    "        b_map.append(F.interpolate(b[item], size=size, mode='bilinear', align_corners=True))\n",
    "    a_map = torch.cat(a_map,1)\n",
    "    b_map = torch.cat(b_map,1)\n",
    "    loss += torch.mean(1-cos_loss(a_map,b_map))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asiclab\\anaconda3\\envs\\RD\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\asiclab\\anaconda3\\envs\\RD\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ConvNeXt_Base_Weights.IMAGENET1K_V1`. You can also use `weights=ConvNeXt_Base_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained weights have been successfully loaded\n"
     ]
    }
   ],
   "source": [
    "encoder = convnext_base(pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asiclab\\anaconda3\\envs\\RD\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNeXt_Base_Weights.verify <bound method WeightsEnum.verify of <enum 'ConvNeXt_Base_Weights'>>\n"
     ]
    }
   ],
   "source": [
    "decoder = de_convnext_base(weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bn = BN_layer(AttnBottleneck,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(_class_):\n",
    "    print(_class_)\n",
    "        \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(device)\n",
    "\n",
    "    data_transform = get_data_transforms(image_size, image_size)\n",
    "    \n",
    "    train_path = './data/' + _class_ + '/train'\n",
    "    ckp_path = './checkpoints/' + 'wres50_'+_class_+'.pth'\n",
    "    \n",
    "    train_data = ImageFolder(root=train_path, transform=data_transform)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # encoder, bn = wide_resnet50_2(pretrained=True)\n",
    "    encoder = convnext_base(pretrained=True)\n",
    "    bn = BN_layer(AttnBottleneck,3)\n",
    "    encoder = encoder.to(device)\n",
    "    bn = bn.to(device)\n",
    "    encoder.eval()\n",
    "    decoder = de_convnext_base(pretrained=False)\n",
    "    decoder = decoder.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(list(decoder.parameters())+list(bn.parameters()), lr=learning_rate, betas=(0.5,0.999))\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time() \n",
    "        \n",
    "        bn.train()\n",
    "        decoder.train()\n",
    "        loss_list = []\n",
    "        for img, label in train_dataloader:\n",
    "            img = img.to(device)\n",
    "            inputs = encoder(img)\n",
    "            outputs = decoder(bn(inputs))#bn(inputs))\n",
    "            loss = loss_fucntion(inputs, outputs)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_list.append(loss.item())\n",
    "        print('epoch [{}/{}], loss:{:.4f}'.format(epoch + 1, epochs, np.mean(loss_list)))\n",
    "        print(\"time :\",time.time() - start)  # 현재시각 - 시작시간 = 실행 시간\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            torch.save({'bn': bn.state_dict(),'decoder': decoder.state_dict()}, ckp_path)\n",
    "            \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습\n",
    "for i in item_list:\n",
    "    start_class = time.time()  # 시작 시간 저장\n",
    "\n",
    "    train(i)\n",
    "    print(i, \"time :\",time.time() - start_class)  # 현재시각 - 시작시간 = 실행 시간"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
